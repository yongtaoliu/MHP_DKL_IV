# -*- coding: utf-8 -*-
"""DGX_DKL_IV_training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mO-kB-5HawYPvCJKz3zHgdAaf4OOg6p0
"""


# !pip install --upgrade torch==1.8.1 torchvision==0.9.1
# !pip install gpytorch botorch
# !pip install atomai
# !pip install mlsocket
# !apt-get update
# !apt install libgl1-mesa-glx

import time
import os
import numpy as np
import pylab as pl
import torch
import gpytorch
import botorch
# import cv2
import atomai as aoi
from atomai import utils
# from scipy.signal import find_peaks
# from sklearn.model_selection import train_test_split
from typing import Union, Type
from mlsocket import MLSocket

############---Acquistion function
def EI(model: Type[aoi.models.dklGPR], X: Union[np.ndarray, torch.Tensor],
       best_f: Union[float, torch.Tensor], xi: Union[float, torch.Tensor] = 0.01,
       batch_size: int = 100) -> np.ndarray:
    """
    Expected Improvement
    """
    tt = torch.tensor
    types = (np.ndarray, np.float32, np.float64, float)
    tor = lambda a: tt(a) if isinstance(a, types) else a    
    device=model.device
    dtype = model.dtype
    X, best_f, xi = tor(X), tor(best_f), tor(xi)
    mean, var = model.predict(X.to(dtype).to(device), batch_size=batch_size)
    mean, var = tor(mean), tor(var)  # have to translate them back to torch tensors
    sigma = var.sqrt()
    u = (mean - best_f.expand_as(mean) - xi.expand_as(mean)) / sigma
    normal = torch.distributions.Normal(torch.zeros_like(u), torch.ones_like(u))
    ucdf = normal.cdf(u)
    updf = torch.exp(normal.log_prob(u))
    obj = sigma * (updf + u * ucdf)
    return obj.detach().cpu().numpy()

structure_image = 'not defined'
features_all = 'not defined'
ws = 'not defined'
n = 'not defined'
d1 = 'not defined'
d2 = 'not defined'
X = 'not defined'
X_train = 'not defined'
X_test = 'not defined'
X_med = 'not defined'
X_test = 'not defined'
y_train = 'not defined'
indices_train = 'not defined'
indices_med = 'not defined'
indices_test = 'not defined'
exploration_steps = 'not defined'

###############----initilized training data
def initialize_traindata():
    global structure_image, features_all, ws, n, d1, d2, imgsize
    global X, X_train, X_test, X_med, X_test, y_train, indices_train, indices_med, indices_test

    image_name = input("structure image name: ")
    imgsize = int(input("structure image size: "))
    structure_image = np.load(image_name)
    coordinates = utils.get_coord_grid(structure_image, 1)

    # extract subimage for each point on a grid
    ws = int(input("patch image window size: "))
    features_all, coords, _ = utils.extract_subimages(structure_image, coordinates, ws)
    features_all = features_all[:,:,:,0]
    print("image patch shape: ", features_all.shape)

    n, d1, d2 = features_all.shape
    X = features_all.reshape(n, d1*d2)
    print("X shape: ", X.shape)

    y_train = np.asarray([])
    X_train = np.zeros((1,int(ws*ws)))
    X_med = np.zeros((1,int(ws*ws)))
    X_test = X
    indices_train = np.zeros((1,2))
    indices_med = np.zeros((1,2))
    indices_test = coords    #check this

###############----dkl parameters
def dkl_parameters():
    global exploration_steps, xi, data_dim
    exploration_steps = int(input("DKL Exploration Steps: "))

    print("DKL exploration step: ", exploration_steps)

############----first point start randomly on V3, add it here
def add_first_point(row, column):
    global X_train, X, X_test, indices_train, indices_test, ws, imgsize
    
    rw = row
    cl = column
    #idx = rw*236 + cl - 10  #idx size is reduced when making image patches
    idx = (rw-int(ws/2))*int(imgsize-ws+1) + cl - int(ws/2)
            
    X_train [0,] = X[idx,]
    X_test = np.delete(X_test, idx, 0)
    indices_train[0,] = indices_test[idx,]
    indices_test = np.delete(indices_test, idx, 0)
    
    print ("X_train shape: ", X_train.shape,
    "\nX_test shape:", X_test.shape,
    "\nindices_train shape: ", indices_train.shape,
    "\nindices_test shape: ", indices_test.shape)


###########----run dkl exploration
def run_dkl():
  global exploration_steps
  global X_train, y_train, indices_train, indices_test, X_test

  #save directory
  print('Provide the data save folder')
  save_folder = input("folder name:")
  savedir = "/AE/{}_record".format(save_folder)

  data_dim = X_train.shape[-1]
  xi = 0.01

  HOST = ''
  PORT = 3446

  with MLSocket() as s:
    s.bind((HOST, PORT))
    print("bounding......\nplease bound the other end")
    s.listen()
    conn, address = s.accept()
    with conn:

      print('measurement starts')

      for step in range(exploration_steps):
        start_time = time.time()
        print("##########----step {}/{}----##########".format(step+1, exploration_steps))

        if step == 0:
            print("add first point data: ")
            x0 = int(input("x: "))
            y0 = int(input("y: "))
            add_first_point(x0, y0)
            #listen to client for measurement result
            measured_point = conn.recv(920)
            print("received new point data")
            #update training data
            y_train = np.append(y_train, measured_point)
        else:
        #listen to client for measurement result
            measured_point = conn.recv(920)
            print("received new point data")
        #update training data
            y_train = np.append(y_train, measured_point)

            X_med[0,] = X_test[next_point_idx,]
            X_train = np.append(X_train, X_med, axis = 0)
            X_test = np.delete(X_test, next_point_idx, 0)
            indices_med[0,] = indices_test[next_point_idx]
            indices_train = np.append(indices_train, indices_med, axis = 0)
            indices_test = np.delete(indices_test, next_point_idx, 0)

        dklgp = aoi.models.dklGPR(data_dim, embedim=2, precision="single")
        dklgp.fit(X_train, y_train, training_cycles=200)
        # Compute acquisition function
        # best_f = torch.tensor(dklgp.predict(X_train)[0].max(), device=dklgp.device)
        # obj_mean = EI(dklgp, X_test, best_f, xi, batch_size = 2000)
        # Select next point to "measure"
        _, var_ = dklgp.predict(X_test, batch_size = len(X_test))
        next_point_idx = var_.argmax()
        next_points = np.asarray(indices_test[next_point_idx])
        #send next point to client
        conn.send(next_points)
        print("send next point idx and next point: ", next_point_idx, next_points)

        # #listen to client for measurement result
        # measured_point = conn.rect(920)
        # print("received new point data")
        # #update training data
        # y_train = np.append(y_train, measured_point)

        # X_med[0,] = X_test[next_point_idx,]
        # X_train = np.append(X_train, X_med, axis = 0)
        # X_test = np.delete(X_test, next_point_idx, 0)
        # indices_med[0,] = indices_test[next_point_idx]
        # indices_train = np.append(indices_train, indices_med, axis = 0)
        # indices_test = np.delete(indices_test, next_point_idx, 0)
        
        #save step record
        np.savez(os.path.join(savedir, "record{}.npz".format(step)), x_train = X_train, y_train = y_train, 
        indice_train = indices_train, indice_test=indices_test, var=var_, nextpoint=next_points)
        # np.savez(("/exp_record/record{}.npz".format(step)), indicestest=indices_test, 
        # objmean=obj_mean, nextpoint=next_points)
        print("time in this step: ", time.time()-start_time)